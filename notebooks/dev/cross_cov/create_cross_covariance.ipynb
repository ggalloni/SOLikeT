{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "import time\n",
    "from pathlib import Path\n",
    "\n",
    "import camb\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import sacc\n",
    "from astropy.io import fits\n",
    "from camb.correlations import lensed_cl_derivatives\n",
    "from cobaya.model import get_model\n",
    "from cobaya.tools import resolve_packages_path\n",
    "from cobaya.yaml import yaml_load_file\n",
    "\n",
    "try:\n",
    "    from numpy import trapezoid\n",
    "except ImportError:\n",
    "    from numpy import trapz as trapezoid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Computing derivatives of CMB power spectra wrt lensing potential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_packages_path = None\n",
    "\n",
    "# Try to resolve global path\n",
    "if custom_packages_path is None:\n",
    "    packages_path = resolve_packages_path()\n",
    "else:\n",
    "    packages_path = custom_packages_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load CMB temperature/polarization data, covariance and bandpowers\n",
    "\n",
    "s = sacc.Sacc.load_fits(\n",
    "    packages_path + \"/data/MFLike/v0.8/data_sacc_w_covar_and_Bbl.fits\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract cosmological parameters, fsky, lmax\n",
    "\n",
    "fsky = float(s.metadata[\"f_sky_LAT\"])\n",
    "cosmo = ast.literal_eval(s.metadata[\"cosmo_params\"])\n",
    "cosmomc_theta = cosmo[\"cosmomc_theta\"]\n",
    "As = 1e-10 * np.exp(cosmo[\"logA\"])\n",
    "ombh2 = cosmo[\"ombh2\"]\n",
    "omch2 = cosmo[\"omch2\"]\n",
    "ns = cosmo[\"ns\"]\n",
    "Alens = cosmo[\"Alens\"]\n",
    "tau = cosmo[\"tau\"]\n",
    "\n",
    "lmax_CMB = int(s.metadata[\"lmax\"]) + 1\n",
    "accuracy_dic = ast.literal_eval(s.metadata['accuracy_params'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute power spectra with CAMB, required to then compute derivatives\n",
    "\n",
    "pars = camb.set_params(\n",
    "    ombh2=ombh2,\n",
    "    omch2=omch2,\n",
    "    cosmomc_theta=cosmomc_theta,\n",
    "    tau=tau,\n",
    "    As=As,\n",
    "    ns=ns,\n",
    "    Alens=Alens,\n",
    "    lmax = lmax_CMB,\n",
    "    lens_potential_accuracy = accuracy_dic['lens_potential_accuracy'],\n",
    "    lens_margin = accuracy_dic['lens_margin'],\n",
    "    AccuracyBoost = accuracy_dic['AccuracyBoost'],\n",
    "    lSampleBoost = accuracy_dic['lSampleBoost'],\n",
    "    lAccuracyBoost = accuracy_dic['lAccuracyBoost'],\n",
    "    kmax = accuracy_dic['kmax'],\n",
    "    k_per_logint = accuracy_dic['k_per_logint'],\n",
    "    nonlinear = accuracy_dic['nonlinear'],\n",
    "    DoLateRadTruncation = accuracy_dic['DoLateRadTruncation'],\n",
    ")\n",
    "\n",
    "\n",
    "pars.set_for_lmax(lmax_CMB)\n",
    "results = camb.get_results(pars)\n",
    "cls = results.get_unlensed_total_cls(CMB_unit=\"muK\")[0 : lmax_CMB + 1, :]\n",
    "clp = results.get_lens_potential_cls(CMB_unit=\"muK\")[0 : lmax_CMB + 1, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute derivatives, takes about 5mn to run\n",
    "\n",
    "t1 = time.time()\n",
    "dCllens = lensed_cl_derivatives(cls, clp)\n",
    "t2 = time.time()\n",
    "print(t2 - t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"products/dCllens.npy\", dCllens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross-covariance CMB primary - CMB lensing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load fiducial lensing yaml file\n",
    "yaml_folder = '../../../examples/smooth/yamls/'\n",
    "yaml_path = Path(yaml_folder)\n",
    "info = yaml_load_file(yaml_folder+\"run_lensing_fiducial.yaml\")\n",
    "\n",
    "model = get_model(info)\n",
    "params_values = model.parameterization.input_params()\n",
    "model.loglikes(params_values)\n",
    "lenslike = model.likelihood['soliket.LensingLikelihood']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lmax_kk = len(lenslike.binning_matrix[0])\n",
    "nb_bins_kk = len(lenslike.binning_matrix)\n",
    "ell_kk = np.arange(lmax_kk)\n",
    "ell_kk_center = lenslike.x\n",
    "cl_kk_fid = np.pi / 2 * lenslike.provider.get_Cl(ell_factor=True)['pp'][0:lmax_kk]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute cross-covariance matrix between l(l+1)/(2*pi)C_l^{TT,EE,TE} and C_l^{kk} \n",
    "# (no prefactor before C_l^{kk})\n",
    "\n",
    "XCov_binned = np.zeros((s.mean.size, nb_bins_kk))\n",
    "\n",
    "index_cmb = 0\n",
    "for comb in s.get_tracer_combinations():\n",
    "    (t1, t2) = comb\n",
    "    if t1[-1] == \"0\" and t2[-1] == \"0\":\n",
    "        # TT case\n",
    "        ind = s.indices(\"cl_00\", comb)\n",
    "        ind_CAMB = 0\n",
    "    elif t1[-1] == \"2\" and t2[-1] == \"2\":\n",
    "        # EE case\n",
    "        ind = s.indices(\"cl_ee\", comb)\n",
    "        ind_CAMB = 1\n",
    "    else:\n",
    "        # TE case\n",
    "        ind = s.indices(\"cl_0e\", comb)\n",
    "        ind_CAMB = 3\n",
    "\n",
    "    bpw = s.get_bandpower_windows(ind)\n",
    "    w = bpw.weight.T  # Shape (k, ell)\n",
    "\n",
    "    # Compute cross-covariance\n",
    "    XCov = 2/np.pi* dCllens[ind_CAMB, bpw.values, :lmax_kk]/clp[0:lmax_kk] \\\n",
    "            *2*cl_kk_fid**2/(2*ell_kk+1)/fsky\n",
    "    XCov[:,0:2] = [0,0]\n",
    "\n",
    "    # Bin cross-covariance\n",
    "    for j in range(nb_bins_kk):\n",
    "        w_kk = lenslike.binning_matrix[j]\n",
    "        XCov_binned[index_cmb:index_cmb + len(w), j] = w @ np.sum(w_kk * XCov, axis=1)\n",
    "\n",
    "    index_cmb += len(w)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "\n",
    "XCorr = copy.deepcopy(XCov_binned)\n",
    "for k in range(len(XCorr)):\n",
    "    for j in range(len(XCorr[0])):\n",
    "        XCorr[k,j] = XCov_binned[k,j]/np.sqrt(lenslike.cov[j,j]*s.covariance.covmat[k,k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 8))\n",
    "plt.imshow(XCorr, aspect=\"auto\")\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save cross-covariance in numpy and fits formats\n",
    "np.save('products/XCov_mflike_lensing.npy', XCov_binned)\n",
    "\n",
    "hdu = fits.PrimaryHDU(data=XCov_binned)\n",
    "hdu.writeto(\"products/XCov_mflike_lensing.fits\", overwrite=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSS cross-covariance ($\\gamma$ x $\\kappa$, CMB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load relevant yaml file\n",
    "info = yaml_load_file(yaml_folder+\"run_shearkappa_fiducial.yaml\")\n",
    "\n",
    "# Need to update datapath because we are not loading the yaml file from the usual location\n",
    "likelihood_name = 'soliket.cross_correlation.ShearKappaLikelihood'\n",
    "datapath = Path(info['likelihood'][likelihood_name]['datapath'])\n",
    "datapath = (yaml_path / datapath).resolve()\n",
    "info['likelihood'][likelihood_name]['datapath'] = datapath\n",
    "\n",
    "model = get_model(info)\n",
    "\n",
    "sklike = model.likelihood[likelihood_name]\n",
    "\n",
    "params_values = model.parameterization.input_params()\n",
    "model.loglikes(params_values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The whole cell is a copy/paste from cross_correlation.py \n",
    "# in order to compute the unbinned cross-correlations\n",
    "ccl, cosmo = sklike._get_CCL_results()\n",
    "\n",
    "cl_binned_list = []\n",
    "cl_unbinned_list = []\n",
    "w_bins_list = []\n",
    "z = []\n",
    "nz = []\n",
    "\n",
    "for tracer_comb in sklike.sacc_data.get_tracer_combinations():\n",
    "    sheartracer_name = tracer_comb[0]\n",
    "\n",
    "    z_tracer1 = sklike.sacc_data.tracers[tracer_comb[0]].z\n",
    "    nz_tracer1 = sklike.sacc_data.tracers[tracer_comb[0]].nz\n",
    "\n",
    "    if sklike.ia_mode is None:\n",
    "        ia_z = None\n",
    "    elif sklike.ia_mode == \"nla\":\n",
    "        A_IA = params_values[\"A_IA\"]\n",
    "        eta_IA = params_values[\"eta_IA\"]\n",
    "        z0_IA = trapezoid(z_tracer1 * nz_tracer1)\n",
    "\n",
    "        ia_z = (z_tracer1, A_IA * ((1 + z_tracer1) / (1 + z0_IA)) ** eta_IA)\n",
    "    elif sklike.ia_mode == \"nla-perbin\":\n",
    "        A_IA = params_values[f\"{sheartracer_name}_A_IA\"]\n",
    "        ia_z = (z_tracer1, A_IA * np.ones_like(z_tracer1))\n",
    "    elif sklike.ia_mode == \"nla-noevo\":\n",
    "        A_IA = params_values[\"A_IA\"]\n",
    "        ia_z = (z_tracer1, A_IA * np.ones_like(z_tracer1))\n",
    "\n",
    "    tracer1 = ccl.WeakLensingTracer(\n",
    "        cosmo, dndz=(z_tracer1, nz_tracer1), ia_bias=ia_z\n",
    "    )\n",
    "\n",
    "    if sklike.z_nuisance_mode is not None:\n",
    "        nz_tracer1 = sklike._get_nz(\n",
    "            z_tracer1, tracer1, tracer_comb[0], **params_values\n",
    "        )\n",
    "\n",
    "        tracer1 = ccl.WeakLensingTracer(\n",
    "            cosmo, dndz=(z_tracer1, nz_tracer1), ia_bias=ia_z\n",
    "        )\n",
    "    z.append(z_tracer1)\n",
    "    nz.append(nz_tracer1)\n",
    "\n",
    "    tracer2 = ccl.CMBLensingTracer(\n",
    "        cosmo, z_source=sklike.provider.get_param(\"zstar\")\n",
    "    )\n",
    "    bpw_idx = sklike.sacc_data.indices(tracers=tracer_comb)\n",
    "    bpw = sklike.sacc_data.get_bandpower_windows(bpw_idx)\n",
    "    ells_theory = bpw.values\n",
    "    ells_theory = np.asarray(ells_theory, dtype=int)\n",
    "    w_bins = bpw.weight.T\n",
    "    w_bins_list.append(w_bins)\n",
    "\n",
    "    cl_unbinned = ccl.cells.angular_cl(cosmo, tracer1, tracer2, ells_theory)\n",
    "\n",
    "    if sklike.m_nuisance_mode is not None:\n",
    "        # note this allows wrong calculation, as we can do\n",
    "        # shear x shear if the spectra are in the sacc\n",
    "        # but then we would want (1 + m1) * (1 + m2)\n",
    "        m_bias = params_values[f\"{sheartracer_name}_m\"]\n",
    "        cl_unbinned = (1 + m_bias) * cl_unbinned\n",
    "\n",
    "    cl_binned = np.dot(w_bins, cl_unbinned)\n",
    "\n",
    "    cl_binned_list.append(cl_binned)\n",
    "    cl_unbinned_list.append(cl_unbinned)\n",
    "\n",
    "cl_binned_total = np.concatenate(cl_binned_list)\n",
    "cl_unbinned_total = np.concatenate(cl_unbinned_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute cross-covariance matrix \n",
    "# between l(l+1)/(2*pi)C_l^{TT,EE,TE} and C_l^{\\gamma\\kappa} \n",
    "\n",
    "XCov_binned = np.zeros((s.mean.size, len(sklike.y)))\n",
    "lmax_lss = len(cl_unbinned_list[0])\n",
    "ell_lss = np.arange(lmax_lss)\n",
    "\n",
    "index_cmb = 0\n",
    "for comb in s.get_tracer_combinations():\n",
    "    (t1, t2) = comb\n",
    "    if t1[-1] == \"0\" and t2[-1] == \"0\":\n",
    "        # TT case\n",
    "        ind = s.indices(\"cl_00\", comb)\n",
    "        ind_CAMB = 0\n",
    "    elif t1[-1] == \"2\" and t2[-1] == \"2\":\n",
    "        # EE case\n",
    "        ind = s.indices(\"cl_ee\", comb)\n",
    "        ind_CAMB = 1\n",
    "    else:\n",
    "        # TE case\n",
    "        ind = s.indices(\"cl_0e\", comb)\n",
    "        ind_CAMB = 3\n",
    "\n",
    "    bpw = s.get_bandpower_windows(ind)\n",
    "    w = bpw.weight.T\n",
    "\n",
    "    # Compute cross-covariance\n",
    "    XCov = []\n",
    "    for k in range(len(cl_unbinned_list)):\n",
    "        XCov.append(2/np.pi*dCllens[ind_CAMB, bpw.values, :lmax_lss]/clp[0:lmax_lss] \\\n",
    "                    *2*cl_unbinned_list[k]**2/(2*ell_lss+1)/fsky)\n",
    "        XCov[k][:,0:2] = [0,0]\n",
    "\n",
    "    # Bin cross-covariance\n",
    "    for k in range(len(cl_unbinned_list)):\n",
    "        w_k = w_bins_list[k]\n",
    "        for j in range(len(w_k)):\n",
    "            XCov_binned[index_cmb:index_cmb + len(w), k*len(w_k)+j] = \\\n",
    "                w @ np.sum(w_k[j] * XCov[k], axis=1)\n",
    "\n",
    "    index_cmb += len(w)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "XCorr = copy.deepcopy(XCov_binned)\n",
    "for k in range(len(XCorr)):\n",
    "    for j in range(len(XCorr[0])):\n",
    "        XCorr[k,j] = XCov_binned[k,j]/np.sqrt(sklike.cov[j,j]*s.covariance.covmat[k,k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 8))\n",
    "plt.imshow(XCorr, aspect=\"auto\")\n",
    "for k in range(1,4):\n",
    "    plt.axvline(x=k*len(w_bins_list[0])-0.5, ls='--', color='black')\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "for k in range(4):\n",
    "    plt.plot(z[k],nz[k], label=f\"bin {k+1}\")\n",
    "plt.legend()\n",
    "plt.xlabel(\"z\")\n",
    "plt.ylabel(\"n(z)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save cross-covariance in numpy and fits formats\n",
    "np.save('products/XCov_mflike_shearkappa.npy', XCov_binned)\n",
    "\n",
    "hdu = fits.PrimaryHDU(data=XCov_binned)\n",
    "hdu.writeto(\"products/XCov_mflike_shearkappa.fits\", overwrite=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lensing induced covariance in CMB primary block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Computes the lensing induced covariance (introduces some mixing between different modes)\n",
    "# Runs in about 4min\n",
    "\n",
    "def f_ind_CAMB(comb):\n",
    "    (t1, t2) = comb\n",
    "    if t1[-1] == '0' and t2[-1] == '0':\n",
    "        ind = s.indices('cl_00', comb)\n",
    "        ind_CAMB = 0\n",
    "    elif t1[-1] == '2' and t2[-1] == '2':\n",
    "        ind = s.indices('cl_ee', comb)\n",
    "        ind_CAMB = 1\n",
    "    else:\n",
    "        ind = s.indices('cl_0e', comb)\n",
    "        ind_CAMB = 3\n",
    "    return (ind, ind_CAMB)\n",
    "\n",
    "Lensing_cov = np.zeros((s.mean.size, s.mean.size))\n",
    "ell3 = np.arange(0, len(clp), 1)\n",
    "factor = 2 / (2 * ell3 + 1) / fsky\n",
    "\n",
    "comb = s.get_tracer_combinations()\n",
    "num_comb = len(comb)\n",
    "\n",
    "cached_data = [\n",
    "    (f_ind_CAMB(comb[i]), s.get_bandpower_windows(f_ind_CAMB(comb[i])[0]))\n",
    "    for i in range(num_comb)\n",
    "]\n",
    "\n",
    "time1 = time.time()\n",
    "for index1 in range(num_comb):\n",
    "    (ind1, ind_CAMB1), bpw1 = cached_data[index1]\n",
    "    w1 = bpw1.weight.T\n",
    "    for index2 in range(index1, num_comb):\n",
    "\n",
    "        (ind2, ind_CAMB2), bpw2 = cached_data[index2]\n",
    "        w2 = bpw2.weight.T\n",
    "\n",
    "        A1 = w1 @ dCllens[ind_CAMB1, bpw1.values]\n",
    "        A2 = w2 @ dCllens[ind_CAMB2, bpw2.values]\n",
    "        product = (A1[:, np.newaxis] * A2[np.newaxis, :]) * factor\n",
    "\n",
    "        Lensing_cov[index1 * len(w1):(index1 + 1) * len(w1),\n",
    "                    index2 * len(w2):(index2 + 1) * len(w2)] = np.sum(product, axis=2)\n",
    "time2 = time.time()\n",
    "print(time2-time1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Lensing_cov_upper_diag = np.triu(Lensing_cov, 0)\n",
    "Lensing_cov_upper = np.triu(Lensing_cov, 1)\n",
    "Lensing_cov_full = Lensing_cov_upper_diag + Lensing_cov_upper.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save lensing induced covariance\n",
    "np.save('products/Lensing_cov.npy', Lensing_cov_full)\n",
    "\n",
    "hdu = fits.PrimaryHDU(data=Lensing_cov_full)\n",
    "hdu.writeto(\"products/Lensing_cov.fits\", overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "XCorr = copy.deepcopy(Lensing_cov_full)\n",
    "for k in range(len(XCorr)):\n",
    "    for j in range(len(XCorr[0])):\n",
    "        XCorr[k,j] = Lensing_cov_full[k,j] \\\n",
    "                        /np.sqrt(s.covariance.covmat[j,j]*s.covariance.covmat[k,k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "plt.imshow(XCorr[0:3000,0:3000], aspect='auto')\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test impact of N1 bias on the cross-covariance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Computes the N1 bias curve. Warning: this cell is very long (almost 1h)\n",
    "# Much of the following cells has been copy/pasted from demo notebook of lensitbiases\n",
    "import lensitbiases as lb\n",
    "from lensitbiases import n0_fft, n1_fft, utils_n1\n",
    "from scipy import signal\n",
    "from scipy.interpolate import InterpolatedUnivariateSpline as spline\n",
    "from scipy.interpolate import UnivariateSpline as spl\n",
    "\n",
    "lminbox=20\n",
    "cls_unl, cls_len, cls_grad = lb.get_default_cls() \n",
    "\n",
    "estimator = 'p'\n",
    "\n",
    "\n",
    "nTf = np.loadtxt('../data/SO_LAT_Nell_T_atmv1_baseline_fsky0p4_ILC_CMB.txt')\n",
    "nPf = np.loadtxt('../data/SO_LAT_Nell_P_baseline_fsky0p4_ILC_CMB_E.txt')\n",
    "nlevT = (np.sqrt(np.concatenate((np.zeros(40),nTf[:,1]))) *60 * 180/np.pi)[:4000+1]\n",
    "nlevP = (np.sqrt(np.concatenate((np.zeros(40),nPf[:,1]))) *60 * 180/np.pi)[:4000+1]\n",
    "\n",
    "fal = utils_n1.get_fal(clscmb_filt=cls_len, clscmb_dat=cls_len, beam=0,\n",
    "                   lmin_ivf=100, lmax_ivf=4000, nlevt=nlevT, nlevp=nlevP, jt_tp=False)[1]\n",
    "\n",
    "lib_n1 = n1_fft.n1_fft(fal, \n",
    "                       cls_len, \n",
    "                       cls_grad, \n",
    "                       cls_unl['pp'], \n",
    "                       lminbox=lminbox, \n",
    "                       lmaxbox=2500*2\n",
    "                      ) \n",
    "\n",
    "Ls_n1 = np.arange(lminbox, 4000+1, 1, dtype=np.int64) #np.linspace(lminbox, 2*2048, 10)\n",
    "\n",
    "res = [lib_n1.get_n1(estimator, L, do_n1mat=True) for L in Ls_n1]\n",
    "\n",
    "n1_SOlike = np.array([r[0] for r in res])\n",
    "n1_mat = np.array([r[1] for r in res]) \n",
    "\n",
    "(R_gg, R_cc), Ls_r = n0_fft.nhl_fft(fal, \n",
    "                                    cls_grad, \n",
    "                                    lminbox=lminbox, \n",
    "                                    lmaxbox=5000\n",
    "                                   ).get_nhl(estimator)\n",
    "normalization = 1/spl(Ls_r, R_gg, k=2, s=0, ext='zeros')(Ls_n1) ** 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gaussian_smooth_1d(data, sigma, nsigma=5):\n",
    "    win = signal.windows.gaussian(nsigma * sigma, std=sigma)\n",
    "    res = np.convolve(data, win, mode='same')\n",
    "    return res / np.convolve(np.ones(data.shape), win, mode='same')\n",
    "\n",
    "a=np.arange(n1_mat.shape[1], dtype=np.int64)\n",
    "nonzero =a[n1_mat[62,:]!=0]\n",
    "diffs = np.concatenate(([10],(nonzero[2:] - nonzero[:-2])/2,[10]))\n",
    "scaled = n1_mat.copy()\n",
    "scaled[:,nonzero] = n1_mat[:,nonzero]/diffs\n",
    "sc = clp[:n1_mat.shape[1]]/(a*(a+1))**2\n",
    "sc[:2]=1\n",
    "N1_mat_smoothed = scaled.copy()\n",
    "for i, L in enumerate(Ls_n1):\n",
    "    N1_mat_smoothed[i,:] = spline(nonzero, \n",
    "                                  gaussian_smooth_1d(scaled[i,nonzero]*sc[nonzero],20)\n",
    "                                 )(a) / sc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fac = (a*(a+1))**2/2/np.pi\n",
    "fac[0]=1\n",
    "minl = min(n1_mat.shape[1], cls_unl['pp'].shape[0])\n",
    "\n",
    "# define n1_normed_mat_smoothed which acts on and returns [L(L+1)]^2/2-like quantities\n",
    "\n",
    "n1_normed_mat_smoothed = fac[Ls_n1,np.newaxis]*normalization[:,np.newaxis] \\\n",
    "                            *N1_mat_smoothed / fac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"products/n1_normed_mat_smoothed.npy\", n1_normed_mat_smoothed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f_ind_CAMB(comb):\n",
    "    (t1, t2) = comb\n",
    "    if t1[-1] == '0' and t2[-1] == '0':\n",
    "        ind = s.indices('cl_00', comb)\n",
    "        ind_CAMB = 0\n",
    "    elif t1[-1] == '2' and t2[-1] == '2':\n",
    "        ind = s.indices('cl_ee', comb)\n",
    "        ind_CAMB = 1\n",
    "    else:\n",
    "        ind = s.indices('cl_0e', comb)\n",
    "        ind_CAMB = 3\n",
    "    return (ind, ind_CAMB)\n",
    "\n",
    "XCov_N1 = np.zeros((s.mean.size,nb_bins_kk))\n",
    "ell3 = np.arange(0, n1_normed_mat_smoothed.shape[1], 1)\n",
    "factor = 2 * clp[0:n1_normed_mat_smoothed.shape[1]] / (2 * ell3 + 1) / fsky\n",
    "factor[1:] *= (2*np.pi) / (ell3[1:]*(ell3[1:]+1))**2\n",
    "\n",
    "comb = s.get_tracer_combinations()\n",
    "num_comb = len(comb)\n",
    "\n",
    "cached_data = [\n",
    "    (f_ind_CAMB(comb[i]), s.get_bandpower_windows(f_ind_CAMB(comb[i])[0]))\n",
    "    for i in range(num_comb)\n",
    "]\n",
    "\n",
    "time1 = time.time()\n",
    "for index1 in range(num_comb):\n",
    "    (ind1, ind_CAMB1), bpw1 = cached_data[index1]\n",
    "    w1 = bpw1.weight.T\n",
    "\n",
    "    A1 = w1 @ dCllens[ind_CAMB1, bpw1.values]\n",
    "    A2 = lenslike.binning_matrix @ n1_normed_mat_smoothed[0:lmax_kk,:]*np.pi/2.\n",
    "    product = (A1[:, np.newaxis, 0:n1_normed_mat_smoothed.shape[1]] * A2[np.newaxis, :]) \\\n",
    "                * factor\n",
    "\n",
    "    XCov_N1[index1 * len(w1):(index1 + 1) * len(w1),:] = np.sum(product, axis=2)\n",
    "time2 = time.time()\n",
    "print(time2-time1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('products/XCov_mflike_lensing_N1.npy', XCov_N1)\n",
    "\n",
    "hdu = fits.PrimaryHDU(data=XCov_N1)\n",
    "hdu.writeto(\"products/XCov_mflike_lensing_N1.fits\", overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot correlation cross-covariance due to N1\n",
    "XCorr = copy.deepcopy(XCov_N1)\n",
    "for k in range(len(XCorr)):\n",
    "    for j in range(len(XCorr[0])):\n",
    "        XCorr[k,j] = XCov_N1[k,j]/np.sqrt(lenslike.cov[j,j]*s.covariance.covmat[k,k])\n",
    "plt.figure(figsize=(8,8))\n",
    "plt.imshow(XCorr, aspect='auto')\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "soliket",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
